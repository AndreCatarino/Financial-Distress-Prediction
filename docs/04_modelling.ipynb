{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM Phase 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this phase, various modeling techniques are selected and applied, and their parameters are calibrated to optimal values. Typically, there are several techniques for the same data mining problem type. Some techniques have specific requirements on the form of data. Therefore, going back to the data preparation phase is often necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import utils\n",
    "import data_processor\n",
    "import cross_validator\n",
    "import model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "data: pd.DataFrame = utils.load_preprocessed_data(\"../data/processed/financial_data_processed.pkl\")\n",
    "\n",
    "# Data preprocessing object\n",
    "processor = data_processor.DataProcessor(data)\n",
    "X, y = processor.create_feature_matrix_and_target_vector(target_column=\"Financial Distress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (70-30) without shuffling (preserve time series order)\n",
    "X_train, _ , y_train, _ = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# TimeSeriesCrossValidator object \n",
    "tscv = cross_validator.TimeSeriesCrossValidator(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get multiple ML models to test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# only models that handle missing values\n",
    "models = [RandomForestClassifier(), SVC(), KNeighborsClassifier(), LogisticRegression()]\n",
    "\n",
    "# Evaluate models with loop to get all metrics and store them in lists\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "model_names = []\n",
    "\n",
    "for model in models:\n",
    "    accuracy, precision, recall, f1, auc = tscv.evaluate(model)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    auc_list.append(auc)\n",
    "    model_names.append(model.__class__.__name__)\n",
    "\n",
    "# Create dataframe with all metrics\n",
    "metrics_df = pd.DataFrame({'Model': model_names, 'Accuracy': accuracy_list, 'Precision': precision_list, 'Recall': recall_list, 'F1': f1_list, 'AUC': auc_list})\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.9732888146911519, 0.9717813051146384, 0.957169459962756, 0.9599198396793587, 0.967391304347826]\n",
      "Mean Score: 0.9659101447591463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1046,    9],\n",
       "       [  41,    6]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train-test split (70-30) without shuffling (preserve time series order)\n",
    "X_train, _ , y_train, _ = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# TimeSeriesCrossValidator object \n",
    "tscv = cross_validator.TimeSeriesCrossValidator(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "scores = tscv.evaluate(rf)\n",
    "\n",
    "print('Scores:', scores)\n",
    "print('Mean Score:', np.mean(scores))\n",
    "\n",
    "# Create a confusion matrix\n",
    "y_pred = rf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score:\n",
      "0.5595643843904407\n"
     ]
    }
   ],
   "source": [
    "# import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('ROC AUC score:')\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimization_forecasting_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
